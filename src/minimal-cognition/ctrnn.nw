\section{CTRNN} \label{blah}

We want to use a Continuous Time Recurrent Neural Network (CTRNN).  A
CTRNN can be described by the following Ordinary Differential Equation
(ODE).

\begin{align}
  \tau_i \dot{y_i} =& -y_i + \sigma(\sum_{j=1}^n w_{ji}y_j - \theta_j) + I_i(t)
\end{align}

\noindent where $\tau_i$ is the time constant of the post-synaptic
node, $y_i$ is the membrane potential of the post-synaptic node,
$w_{ji}$ is the weight of the connection from the pre- to
post-synaptic node, $\sigma(x)$ is the sigmoidal function $\sigma(x) =
1/(1 + e^{-x})$, $\theta_i$ is the bias, and $I_i(t)$ is the input if
any at time $t$.  See
\href{http://en.wikipedia.org/wiki/Recurrent_neural_network#Continuous-time_RNN}{wikipedia}
for more details.  It can be expressed more compactly using matrices.

\begin{align} \label{dot_y1}
  T\circ\dot{Y} =& -Y + \Sigma(W\,Y - \Theta) + I(t) 
\end{align}

Beer, however, uses a slightly different form than the one shown above

\begin{align}
  \tau_i \dot{y_i} =& -y_i + \sum_{j=1}^n w_{ji}\sigma(g_j(y_j + \theta_j)) + I_i(t)
\end{align}

\noindent where $g_j$ is the gain.  In matrix form it is

\begin{align}
  T\circ\dot{Y} =& -Y + W\,\sigma(G \circ(Y +
 \Theta)) + I(t) \text{.}\label{dot_y2}
\end{align}

\subsection{Implementation}

The implementation will use the
\href{http://www.gnu.org/software/gsl/}{GNU Scientific Library (GSL)}
for its linear algebra needs.

<<file:ctrnn.h>>=
#ifndef _CTRNN_H_
#define _CTRNN_H_
#include <stddef.h>
#include <stdlib.h>

typedef struct ctrnn_params {
  size_t  n; /* number of nodes */
  const double *weights; /* n x n real numbers */
  const double *time_constant; /* n real numbers */
  const double *bias; /* n real numbers */
  const double *gain;
  //ctrnn_input input;
  int (*input)(double t, int i, struct ctrnn_params *params, double *output);
  void   *user;
} ctrnn_params;

typedef int (*ctrnn_input)(double t, int i, struct ctrnn_params *params, double *output);

//int dot_y(double t, const double *y, double *dydt, void *params);
int dot_y1(double t, const double *y, double *dydt, void *params);
int dot_y2(double t, const double *y, double *dydt, void *params);

int step_ctrnn(double *ty, double h, ctrnn_params *params);
#endif /* _CTRNN_H_ */
@ 
  
First thing we'd like to do is compute the $\dot{Y}$ \cref{dot_y1}
vector for our given CTRNN, and we won't be using a method that
requires the Jacobian.

<<Function>>=
int dot_y1(double t, const double *y, double *dydt, void *params)
{
  ctrnn_params *cparams = (ctrnn_params *) params;
               <<Weird testing.>>
  <<Compute $R \set W \, Y - \Theta$.>>
  <<Compute $R \set \Sigma(R)$.>>
  <<Compute $R \set R - Y$.>>
  <<Compute $R \set R + I(t)$.>>
  <<Compute $R \set R \circ T^{-1}$.>>
  return GSL_SUCCESS;
}
@ % dot_y1

<<Function>>=
int dot_y2(double t, const double *y, double *dydt, void *params)
{
  ctrnn_params *cparams = (ctrnn_params *) params;
  <<Compute $R \set Y + \Theta$.>>
  <<Compute $R \set G \circ R$.>>
  <<Compute $R \set \Sigma(R)$.>>
  <<Compute $R \set W \, R$.>>
  <<Compute $R \set R - Y$.>>
  <<Compute $R \set R + I(t)$.>>
  <<Compute $R \set R \circ T^{-1}$.>>
  return GSL_SUCCESS;
}
@ 

To advance the ODE we will use the same skeleton outlined 
\href{http://www.gnu.org/software/gsl/manual/html_node/ODE-Example-programs.html}{here}.

<<Function>>=
int step_ctrnn(double *ty, double h, ctrnn_params *params)
{
  double *y = ty + 1;
  double *t = ty;
  gsl_odeiv2_system sys = {&dot_y1, 
                           NULL, 
                           params->n, 
                           params};
  gsl_odeiv2_driver * d = 
         gsl_odeiv2_driver_alloc_y_new (&sys, gsl_odeiv2_step_rkf45,
                                        1e-2, 1e-6, 0.0);

  int status = gsl_odeiv2_driver_apply (d, t, *t + h, y);
     
  gsl_odeiv2_driver_free (d);
  return status;
}
@ 

\subsection{Again, But With More Scheme!}

<<Primitive>>=

#define C_STRING_TO_SYMBOL(str) scm_string_to_symbol(scm_from_locale_string(str))

SCM_DEFINE (scm_step_ctrnn, "step-ctrnn*", 8, 0, 0,
            (SCM ty, SCM h, SCM n, SCM weights, 
             SCM time_constant, SCM bias, SCM gain, SCM input_func),
            "Move a CTRNN forward a single time step.")
{
#define GET_DOUBLE_HANDLE(scm_var, double_array) \
  scm_t_array_handle scm_var ## _handle; \
  scm_array_get_handle(scm_var, &scm_var ## _handle); \
  double* double_array = scm_array_handle_f64_writable_elements(&scm_var ## _handle);

#define GET_READ_DOUBLE_HANDLE(scm_var, double_array) \
  scm_t_array_handle scm_var ## _handle; \
  scm_array_get_handle(scm_var, &scm_var ## _handle); \
  const double* double_array = scm_array_handle_f64_elements(&scm_var ## _handle);

#define RELEASE_HANDLE(scm_var) \
  scm_array_handle_release(&scm_var ## _handle);

  GET_DOUBLE_HANDLE(ty, ty_array);
  GET_READ_DOUBLE_HANDLE(weights, w_array);
  GET_READ_DOUBLE_HANDLE(time_constant, tc_array);
  GET_READ_DOUBLE_HANDLE(bias, b_array);
  GET_READ_DOUBLE_HANDLE(gain, g_array);
  int err;
  ctrnn_params params;
  params.n = scm_to_int(n);
  params.weights = w_array;
  params.time_constant = tc_array;
  params.bias = b_array;
  params.gain = g_array;
  if (scm_is_false(input_func)) {
    params.input = NULL;
    params.user = NULL;
  } else if (scm_is_true(scm_procedure_p (input_func))) {
    params.input = call_scm_input_func;
    params.user = input_func;
  } else if (scm_is_true(scm_list_p (input_func))) {
    SCM list = input_func;
    
    if (scm_is_false(scm_eq_p(scm_car(list), 
                              C_STRING_TO_SYMBOL("c-vision-input")))) {
      scm_throw(C_STRING_TO_SYMBOL("invalid-list-input-func"), SCM_EOL);
    }
    list = scm_cdr(list); // Skip element 0.

    params.input = vision_input; // C vision implementation.
    struct vision_args vargs;
    vargs.ty = ty_array;
    list = scm_cdr(list); // Skip element 1.
    vargs.m = scm_to_int(scm_car(list));
    list = scm_cdr(list); 
    vargs.n = scm_to_int(scm_car(list));
    list = scm_cdr(list); 
    vargs.d = scm_to_double(scm_car(list));
    list = scm_cdr(list); 
    vargs.r = scm_to_double(scm_car(list));
    list = scm_cdr(list); 
    vargs.D = scm_to_double(scm_car(list));
    list = scm_cdr(list); 
    vargs.Theta = scm_to_double(scm_car(list));
    list = scm_cdr(list); 
    vargs.max_output = scm_to_double(scm_car(list));
    list = scm_cdr(list); 
    vargs.R = NULL;
    setup_vision_args(&vargs);
    params.user = &vargs;
  } else {
    scm_throw(C_STRING_TO_SYMBOL("invalid-input-func"), SCM_EOL);
    return SCM_BOOL_F;
  }
  err = step_ctrnn(ty_array, scm_to_double(h), &params);

  //teardown_vision_args(params.user);

  RELEASE_HANDLE(ty);
  RELEASE_HANDLE(weights);
  RELEASE_HANDLE(time_constant);
  RELEASE_HANDLE(bias);
  RELEASE_HANDLE(gain);
  return err == 0 ? SCM_BOOL_T : SCM_BOOL_F;
}
@ 

<<Function>>=
int call_scm_input_func(double t, int i, struct ctrnn_params *params, double *output)
{
  SCM res = scm_call_2((SCM) params->user, scm_from_double(t), scm_from_int(i));
  *output = scm_to_double(res);
  return 0;
}
@ 

<<Initialize>>=
void init_ctrnn(void)
{
#ifndef SCM_MAGIC_SNARFER 
#include "ctrnn.c.x" 
#endif
}
@
<<file:ctrnn.scm>>=
(define-module (minimal-cognition ctrnn)
 #:use-module (ice-9 optargs)
 #:use-module (oop goops)
 #:use-module ((vector-math) #:select (vector-move!*))
 #:use-module (emacsy util))

;; This is erroneously reported as a "file not found" error when
;; there is a symbol missing.
(load-extension "/Users/shane/School/uvm/CSYS-395-evolutionary-robotics/noweb-eracs/ctrnn/src/minimal-cognition/libguile-ctrnn" "init_ctrnn")

<<Class>>

<<Procedure>>
@

<<Procedure>>=
(define-public (step-ctrnn yt h ctrnn)
 (step-ctrnn* 
  yt
  h 
  (n ctrnn)
  (weights ctrnn)
  (time-constant ctrnn)
  (bias ctrnn)
  (gain ctrnn)
  (input-func ctrnn)))
@ 

<<Class>>=
(define-class <ctrnn> ()
 (n #:getter n #:init-keyword #:n)
 (weights #:accessor weights #:init-keyword #:weights)
 (time-constant #:getter time-constant #:init-keyword #:time-constant)
 (bias #:getter bias #:init-keyword #:bias)
 (gain #:getter gain #:init-keyword #:gain)
 (input-func #:accessor input-func #:init-keyword #:input-func))

 (export <ctrnn> input-func)
@ 

<<Procedure>>=
 (define*-public (make-n-ctrnn n #:optional (input-func #f))
  (make <ctrnn> #:n n
                #:weights (make-typed-array 'f64 0.0 (* n n))
                #:time-constant (make-typed-array 'f64 1.0 n)
                #:bias (make-typed-array 'f64 0.0 n)
                #:gain (make-typed-array 'f64 1.0 n)
                #:input-func input-func
  )
 )

(define* (vector-map! f v #:optional (i 0))
  "Changes the vector in place."
  (if (< i (generalized-vector-length v))
      (begin
        (generalized-vector-set! v i (f (generalized-vector-ref v i) i))
        (vector-map! f v (1+ i)))
      v))

(define-public (randomize-ctrnn! ctrnn)
 (define (random-weight)
  (- 5 (random 10.)))
 (vector-map! (lambda (x i)
               (random-weight)) (weights ctrnn)))

(define-public (make-ctrnn-state ctrnn)
 (make-typed-array 'f64 0.0 (1+ (* 2 (n ctrnn))))
  )
@ 

Now let's test it.  
<<test>>=
(define (copy-array a) 
  (let ((b (apply make-typed-array (array-type a) 0. (array-shape a))))
    (array-copy! a b)
    b))
(define y (copy-array #f64(0.0 0.1)))
(check y (=> (=? 0.0001)) #f64(0.0 0.1))
(check (procedure? make-n-ctrnn) => #t)
(define c (make-n-ctrnn 1))
(check (time-constant c) => #f64(1.0))
(check (bias c) => #f64(0.0))
(check (gain c) => #f64(1.0))
(check (weights c) => #f64(0.0))
(check (array-dimensions (time-constant c)) => '(1))
(check (step-ctrnn y 0.01 c) => #t)
(define y* (copy-array #f64(0.01 0.10398)))
(check y (=> =?) y*)
(set! y (copy-array #f64(0.0 0.1)))
(check y (=> =?) #f64(0.0 0.1))
(check (step-ctrnn y 0.01 c) => #t)
(check y (=> =?) y*)
@ 

Let's test whether the input will make a difference.

<<test>>=
(set! y #f64(0.0 0.1))
(define c2 (make-n-ctrnn 1 (lambda (t i) 1.)))
(check (step-ctrnn y 0.01 c2) => #t)
(check y (=> (negate =?)) y*)
@ 

\subsection{Evolving the CTRNN}

To evolve the CTRNN using something like NSGA-II, we'll need to be
able to convert a genome to into a CTRNN, and though not strictly
necessary, it'd be nice to be able to convert a CTRNN into a genome.

<<Procedure>>=
(define-public (make-genome-for-n-ctrnn n)
  (let ((m ;; number of genes
         (+ 
          (* n n) ;;weights
          n ;; time-constants
          n ;; bias
          n ;; gain
          
          )))
   (make-typed-array 'f64 0. m)))
@ 

Let's make a procedure to randomize the genome.  We'll assume the gene
values are in $[-1, 1]$.

<<Procedure>>=
(define-public (randomize-genome! genome)
 (define (random-gene)
   (- 1. (random 2.)))
 (vector-map! (lambda (x i)
               (random-gene)) genome))
@

Now, let's convert this genome to a ctrnn.

<<Procedure>>=
(define-public (genome->ctrnn genome ctrnn)
  (define (remap a b vector)
    (vector-map! (lambda (x i)
                   (+ a (* (/ (+ x 1.0) 2) (- b a)))) vector))
  (let ((n (n ctrnn))
        (i 0))
    (remap -5 5 (vector-move!* (weights ctrnn) 0 (1- (* n n)) genome i (1- (incr! i (* n n)))))
   
    (remap 1 2 (vector-move!* (time-constant ctrnn) 0 (1- n) genome i (1- (incr! i n))))
    (remap -10 0 (vector-move!* (bias ctrnn)          0 (1- n) genome i (1- (incr! i n))))
    (remap 1 5 (vector-move!* (gain ctrnn)          0 (1- n) genome i (1- (incr! i n)))))
  ctrnn)
@ 

<<test>>=
(define genome (make-genome-for-n-ctrnn 3))
(randomize-genome! genome)
(define c3 (make-n-ctrnn 3))

(genome->ctrnn genome c3)
@ 

\appendix
