% -*- mode: Noweb; noweb-code-mode: c-mode -*-
\section{CTRNN} \label{blah}

We want to use a Continuous Time Recurrent Neural Network (CTRNN).  A
CTRNN can be described by the following Ordinary Differential Equation
(ODE).

\begin{align}
  \tau_i \dot{y_i} =& -y_i + \sigma(\sum_{j=1}^n w_{ji}y_j - \theta_j) + I_i(t)
\end{align}

\noindent where $\tau_i$ is the time constant of the post-synaptic
node, $y_i$ is the membrane potential of the post-synaptic node,
$w_{ji}$ is the weight of the connection from the pre- to
post-synaptic node, $\sigma(x)$ is the sigmoidal function $\sigma(x) =
1/(1 + e^{-x})$, $\theta_i$ is the bias, and $I_i(t)$ is the input if
any at time $t$.  See
\href{http://en.wikipedia.org/wiki/Recurrent_neural_network#Continuous-time_RNN}{wikipedia}
for more details.  It can be expressed more compactly using matrices.

\begin{align} \label{dot_y1}
  T\circ\dot{Y} =& -Y + \Sigma(W\,Y - \Theta) + I(t) 
\end{align}

Beer, however, uses a slightly different form than the one shown above

\begin{align}
  \tau_i \dot{y_i} =& -y_i + \sum_{j=1}^n w_{ji}\sigma(g_j(y_j + \theta_j)) + I_i(t)
\end{align}

\noindent where $g_j$ is the gain.  In matrix form it is

\begin{align}
  T\circ\dot{Y} =& -Y + W\,\sigma(G \circ(Y +
 \Theta)) + I(t) \text{.}\label{dot_y2}
\end{align}

\subsection{Implementation}

The implementation will use the
\href{http://www.gnu.org/software/gsl/}{GNU Scientific Library (GSL)}
for its linear algebra needs.

<<file:ctrnn.h>>=
#include <stddef.h>
#include <stdlib.h>

typedef struct ctrnn_params {
  size_t  n; /* number of nodes */
  double *weights; /* n x n real numbers */
  double *time_constant; /* n real numbers */
  double *bias; /* n real numbers */
  double *gain;
  double (*input)(double t, int i, struct ctrnn_params *params);
  void   *user;
} ctrnn_params;

//int dot_y(double t, const double *y, double *dydt, void *params);
int dot_y1(double t, const double *y, double *dydt, void *params);
int dot_y2(double t, const double *y, double *dydt, void *params);

int step_ctrnn(double *ty, double h, ctrnn_params *params);
@ 
  
First thing we'd like to do is compute the $\dot{Y}$ \ref{dot_y1}
vector for our given CTRNN, and we won't be using a method that
requires the Jacobian.

<<Function>>=
int dot_y1(double t, const double *y, double *dydt, void *params)
{
  ctrnn_params *cparams = (ctrnn_params *) params;
  <<Compute $R \set W \, Y - \Theta$.>>
  <<Compute $R \set \Sigma(R)$.>>
  <<Compute $R \set R - Y$.>>
  <<Compute $R \set R + I(t)$.>>
  <<Compute $R \set R \circ T^{-1}$.>>
  return GSL_SUCCESS;
}
@ 

<<Function>>=
int dot_y2(double t, const double *y, double *dydt, void *params)
{
  ctrnn_params *cparams = (ctrnn_params *) params;
  <<Compute $R \set Y + \Theta$.>>
  <<Compute $R \set G \circ R$.>>
  <<Compute $R \set \sigma(R)$.>>
  <<Compute $R \set W \, R$.>>
  <<Compute $R \set R - Y$.>>
  <<Compute $R \set R + I(t)$.>>
  <<Compute $R \set R \circ T^{-1}$.>>
  return GSL_SUCCESS;
}
@ 

To advance the ODE we will use the same skeleton outlined 
\href{http://www.gnu.org/software/gsl/manual/html_node/ODE-Example-programs.html}{here}.

<<Function>>=
int step_ctrnn(double *ty, double h, ctrnn_params *params)
{
  double *y = ty + 1;
  double *t = ty;
  gsl_odeiv2_system sys = {&dot_y1, 
                           NULL, 
                           params->n, params};
  gsl_odeiv2_driver * d = 
         gsl_odeiv2_driver_alloc_y_new (&sys, gsl_odeiv2_step_rkf45,
                                        1e-2, 1e-6, 0.0);

  int status = gsl_odeiv2_driver_apply (d, t, *t + h, y);
     
  gsl_odeiv2_driver_free (d);
  return status;
}
@ 

\subsection{Again, But With More Scheme!}

<<Primitive>>=
SCM_DEFINE (scm_step_ctrnn, "step-ctrnn*", 8, 0, 0,
            (SCM ty, SCM h, SCM n, SCM weights, 
             SCM time_constant, SCM bias, SCM gain, SCM input_func),
            "Move a CTRNN forward a single time step.")
{
#define GET_DOUBLE_HANDLE(scm_var, double_array) \
  scm_t_array_handle scm_var ## _handle; \
  scm_array_get_handle(scm_var, &scm_var ## _handle); \
  double* double_array = scm_array_handle_f64_writable_elements(&scm_var ## _handle);

#define GET_READ_DOUBLE_HANDLE(scm_var, double_array) \
  scm_t_array_handle scm_var ## _handle; \
  scm_array_get_handle(scm_var, &scm_var ## _handle); \
  double* double_array = scm_array_handle_f64_elements(&scm_var ## _handle);

#define RELEASE_HANDLE(scm_var) \
  scm_array_handle_release(&scm_var ## _handle);

  GET_DOUBLE_HANDLE(ty, ty_array);
  GET_READ_DOUBLE_HANDLE(weights, w_array);
  GET_READ_DOUBLE_HANDLE(time_constant, tc_array);
  GET_READ_DOUBLE_HANDLE(bias, b_array);
  GET_READ_DOUBLE_HANDLE(gain, g_array);

  ctrnn_params params;
  params.n = scm_to_int(n);
  params.weights = w_array;
  params.time_constant = tc_array;
  params.bias = b_array;
  params.gain = g_array;
  if (scm_is_false(input_func)) {
    params.input = NULL;
    params.user = NULL;
  } else {
    params.input = call_scm_input_func;
    params.user = input_func;
  }
  step_ctrnn(ty_array, scm_to_double(h), &params);

  RELEASE_HANDLE(ty);
  RELEASE_HANDLE(weights);
  RELEASE_HANDLE(time_constant);
  RELEASE_HANDLE(bias);
  return SCM_BOOL_T;
}
@ 

<<Function>>=
double call_scm_input_func(double t, int i, struct ctrnn_params *params)
{
  SCM res = scm_call_2((SCM) params->user, scm_from_double(t), scm_from_int(i));
  return scm_to_double(res);
}
@ 

<<Initialize>>=
void init_ctrnn(void)
{
#ifndef SCM_MAGIC_SNARFER 
#include "ctrnn.c.x" 
#endif
}
@
<<file:ctrnn.scm>>=
(define-module (minimal-cognition ctrnn)
 #:use-module (ice-9 optargs)
 #:use-module (oop goops))

;;(load-extension "libguile-ctrnn.dylib" "init_ctrnn")
;; This is erroneously reported as a "file not found" error when
;; there is a symbol missing.
(load-extension "libguile-ctrnn.la" "init_ctrnn")

<<Class>>

<<Procedure>>
@

<<Procedure>>=
(define-public (step-ctrnn yt h ctrnn)
 (step-ctrnn* 
  yt
  h 
  (car (array-dimensions (time-constant ctrnn)))
  (weights ctrnn)
  (time-constant ctrnn)
  (bias ctrnn)
  (gain ctrnn)
  (input-func ctrnn)))
@ 

<<Class>>=
(define-class <ctrnn> ()
 (weights #:getter weights #:init-keyword #:weights)
 (time-constant #:getter time-constant #:init-keyword #:time-constant)
 (bias #:getter bias #:init-keyword #:bias)
 (gain #:getter gain #:init-keyword #:gain)
 (input-func #:getter input-func #:init-keyword #:input-func))
@ 

<<Procedure>>=
 (define*-public (make-n-ctrnn n #:optional (input-func #f))
  (make <ctrnn> #:weights (make-typed-array 'f64 0.0 (* n n))
                #:time-constant (make-typed-array 'f64 1.0 n)
                #:bias (make-typed-array 'f64 0.0 n)
                #:gain (make-typed-array 'f64 1.0 n)
                #:input-func input-func
  )
 )
@ 

Now let's test it.  
<<test>>=
(define y #f64(0.0 0.1))
(check (procedure? make-n-ctrnn) => #t)
(define c (make-n-ctrnn 1))
(check (time-constant c) => #f64(1.0))
(check (array-dimensions (time-constant c)) => '(1))
(check (step-ctrnn y 0.01 c) => #t)
(check y (=> =?) #f64(0.01 0.10398))
@ 

Let's test whether the input will make a difference.

<<test>>=
(set! y #f64(0.0 0.1))
(define c2 (make-n-ctrnn 1 (lambda (t i) 1.)))
(check (step-ctrnn y 0.01 c2) => #t)
(check y (=> (negate =?)) #f64(0.01 0.10398))
@ 

\appendix
\input{ctrnn.appendix}
